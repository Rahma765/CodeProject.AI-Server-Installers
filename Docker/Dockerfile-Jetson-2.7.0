# CodeProject.AI Server
#
# See https://github.com/ultralytics/ultralytics/blob/main/docker/Dockerfile-jetson
# DOCKER Image build file for Jetson. It contains CUDA 10.2
# 
# docker run --name CodeProject.AI -d
# -p 32168:32168 -p 32168:32168/udp \
# --mount type=bind,source=/etc/codeproject/ai,target=/etc/codeproject/ai \
# --mount type=bind,source=/opt/codeproject/ai,target=/app/modules \
# --gpus all codeproject/ai-server:jetson
#
#
# ASSUMPTION: This is being build from the root directory of the solution. This
# is set in the build_docker script as the last param to the docker buildx command,
# namely the "../..". This takes us from /Installers/Docker to /. and then this
# image file proceeds
#
# BE AWARE: this cuDNN equipped build may lock up when two YOLO equipped modules
# are installed on it. Without cuDNN, .NET ONNX runtime for GPU doesn't work.

# INITIAL SETUP ===============================================================

# Note: we're before the first 'FROM' statment so these values are not available
# inside the build stages. If you wish to use these inside a stage, re-grab them 
# inside that stage
ARG CUDA_VERSION=10.2
ARG CUDA_MAJOR=11
ARG UBUNTU_VERSION=18.04
ARG DOTNET_VERSION=8.0
ARG CPAI_VERSION

# FROM nvcr.io/nvidia/l4t-cuda:10.2.460-runtime as base - no longer available
FROM gpuci/cuda-l4t:$CUDA_VERSION-runtime-ubuntu$UBUNTU_VERSION as base

# CUDA SETUP ===================================================================

# NOTE: NVIDIA no longer hosts the packages needed for CUDA10.2 so setup is no
#       longer possible in this form

# RUN echo "NV_CUDA_LIB_VERSION      = $NV_CUDA_LIB_VERSION"
# RUN echo "NV_NVML_DEV_VERSION      = $NV_NVML_DEV_VERSION"
# RUN echo "NV_LIBNPP_DEV_VERSION    = $NV_LIBNPP_DEV_VERSION"
# RUN echo "NV_LIBCUBLAS_DEV_PACKAGE = $NV_LIBCUBLAS_DEV_PACKAGE"
# RUN echo "NV_LIBNCCL_DEV_PACKAGE   = $NV_LIBNCCL_DEV_PACKAGE"
#
# RUN apt-get update && apt-get install -y --no-install-recommends \
#     cuda-nvml-dev-10-2=${NV_NVML_DEV_VERSION} \
#     cuda-command-line-tools-10-2=${NV_CUDA_LIB_VERSION} \
#     cuda-nvprof-10-2=${NV_CUDA_LIB_VERSION} \
#     cuda-npp-dev-10-2=${NV_LIBNPP_DEV_VERSION} \
#     cuda-libraries-dev-10-2=${NV_CUDA_LIB_VERSION} \
#     cuda-minimal-build-10-2=${NV_CUDA_LIB_VERSION} \
#     ${NV_LIBCUBLAS_DEV_PACKAGE} \
#     ${NV_LIBNCCL_DEV_PACKAGE} \
#    && rm -rf /var/lib/apt/lists/*
#
# apt from auto upgrading the cublas package. See https://gitlab.com/nvidia/container-images/cuda/-/issues/88
# RUN apt-mark hold ${NV_LIBCUBLAS_DEV_PACKAGE_NAME} ${NV_LIBNCCL_DEV_PACKAGE_NAME}
#
# ENV LIBRARY_PATH /usr/local/cuda/lib64/stubs

# END CUDA SETUP ===============================================================

WORKDIR /app

# Replace the sudo command, which doesn't exist in this image, with a noop so
# our scripts, which do contain sudo calls, will work
RUN if ! type sudo 2>/dev/null; then echo "#!/bin/sh\n\${@}" > /usr/sbin/sudo; chmod +x /usr/sbin/sudo; fi

# Environment vars ------------------------------------------------------------
 
ENV ASPNETCORE_URLS=http://+:32168;http://+:5000

# The simple log format is easier on my brain than json
ENV LOGGING__CONSOLE__FORMATTERNAME=simple

# Magic that was being done by the Microsoft ASP.NET base image that we aren't using anymore
ENV DOTNET_RUNNING_IN_CONTAINER=true

# noninteractive frontend means no prompts or questions are asked and whenever a call requires an
# answer, the default will be used. Installs will be non-interrupted and so won't hang. The Python
# installs, for instance, require this in this current environment
ENV DEBIAN_FRONTEND noninteractive

# Grab the values passed in via command line here so we can use inside this stage
ARG UBUNTU_VERSION=22.04
ARG DOTNET_VERSION=8.0
ARG CPAI_VERSION

ENV CPAI_VERSION=$CPAI_VERSION
ENV UBUNTU_VERSION=$UBUNTU_VERSION
ENV DOTNET_VERSION=$DOTNET_VERSION

# Setup the ports -------------------------------------------------------------

EXPOSE 5000
EXPOSE 32168/tcp
EXPOSE 32168/udp

# Add some labels to the container --------------------------------------------

LABEL "Application"="CodeProject.AI Server"
LABEL "Publisher"="CodeProject Solutions Inc"
LABEL "Version"="${CPAI_VERSION}"
LABEL "Target"="Jetson (arm64) specific ${UBUNTU_VERSION} with CUDA ${CUDA_VERSION}"
LABEL "Description"="CodeProject.AI Server for Jetson (arm64) on ${UBUNTU_VERSION} with CUDA ${CUDA_VERSION}."


# Install required libraries --------------------------------------------------

# Install packages. In order:
#
# Required for SkiaSharp
#   libfontconfig1
# Required for System.Drawing
#   libgdplus
#   libjpeg-dev (maybe?)
#   zlib1g-dev (maybe?)
# Needed for opencv-python
#   ffmpeg libsm6 libxext6 libc6-dev
# So we can query glxinfo for GPU info
#   mesa-utils
# So we can install modules
#   curl jq unzip wget rsync ca-certificates (ca-certificates so we can do --no-check-certificate, jq for json parsing)
# This stops the "lsmod: not found" error
#   kmod

RUN apt-get update -y && apt-get install -y --no-install-recommends \
    libfontconfig1  \
    libgdiplus      \
    libjpeg-dev     \
    zlib1g-dev      \
                    \
    ffmpeg          \
    libc6-dev       \
    libsm6          \
    libxext6        \
                    \
    mesa-utils      \
                    \
    ca-certificates \
    curl            \
    jq              \
    rsync           \
    unzip           \
    wget            \
                    \
    psmisc          \
                    \
    kmod            > /dev/null

    # Not needed. Probably.
    # apt-utils


# .NET ------------------------------------------------------------------------

# Update packages and install NET

# See https://learn.microsoft.com/en-us/dotnet/core/install/linux-scripted-manual#scripted-install
RUN wget https://dot.net/v1/dotnet-install.sh -O dotnet-install.sh
RUN chmod +x ./dotnet-install.sh
# Install .NET. For just the runtime use "--channel $DOTNET_VERSION --runtime aspnetcore"
RUN ./dotnet-install.sh --channel $DOTNET_VERSION --runtime aspnetcore
# The install script is for CI/CD and doesn't actually register .NET. So add 
# link and env variable
RUN ln -fs $HOME/.dotnet/dotnet /usr/local/bin/dotnet
RUN echo 'export DOTNET_ROOT=~/.dotnet' >> $HOME/.bashrc
RUN echo 'export PATH=$PATH:$DOTNET_ROOT' >> $HOME/.bashrc


# Setup Python ----------------------------------------------------------------

# Allow us to get older, deceased Python packages from dead snakes
RUN apt-get install software-properties-common -y && \
    add-apt-repository ppa:deadsnakes/ppa -y

# This (currently) installs python3.8 as a dependency. It could be in the future
# that a different version of python is installed instead, in which case we may
# need to pin the installed python version.
RUN apt-get install python3-pip python3-apt python3-setuptools -y

# Install Python3.8, distutils and dev tools (so packages can be built if needed)
# and pip install so we can install python packages
RUN apt-get install python3.8 -y && \
    apt-get install python3.8-distutils -y && \
    apt-get install python3.8-dev -y && \ 
    python3.8 -m pip install --upgrade setuptools && \
    python3.8 -m pip install --upgrade pip

# install virtual env tools
RUN apt install python3.8-venv -y && \
    python3.8 -m pip install virtualenv virtualenvwrapper


# Install Python3.9, distutils and dev tools (so packages can be built if needed)
# and pip install so we can install python packages
# RUN apt-get install python3.9 -y && \
#    apt-get install python3.9-distutils -y && \
#    apt-get install python3.9-dev -y && \ 
#    python3.9 -m pip install --upgrade setuptools && \
#    python3.9 -m pip install --upgrade pip

# install virtual env tools
#RUN apt install python3.9-venv -y
#RUN python3.9 -m pip install virtualenv virtualenvwrapper


# Build the .NET source in a separate, discardable build container --------------

FROM mcr.microsoft.com/dotnet/sdk:$DOTNET_VERSION AS build

# A new image so we need to re-declare these
# See https://docs.docker.com/engine/reference/builder/#scope
ARG UBUNTU_VERSION=22.04
ARG DOTNET_VERSION=8.0
ARG CPAI_VERSION
ARG REPO_NAME
ARG MODULES_REPO_NAME=CodeProject.AI-Modules

ENV CPAI_VERSION=$CPAI_VERSION
ENV UBUNTU_VERSION=$UBUNTU_VERSION
ENV DOTNET_VERSION=$DOTNET_VERSION
ENV REPO_NAME=$REPO_NAME
ENV MODULES_REPO_NAME=$MODULES_REPO_NAME

# change directory to /src in the build image
WORKDIR /src

# Copy only the bits we need to for the .NET compilation steps
COPY /${REPO_NAME}/src/server/                        src/server/
COPY /${REPO_NAME}/src/SDK/                           src/SDK/
COPY /${REPO_NAME}/src/scripts/                       src/scripts/

# Build and publish Server
WORKDIR "/src/src/server"
RUN dotnet publish "Server.csproj" -c Release --no-self-contained --force -o /app/publish/server

# Build and publish .NET modules, copy over docker-specific modulesettings, and 
# then copy over models

# ** No .NET modules for this image


# BEGIN REVIEW ================================================================

# REVIEW: [Matthew] This section should go in the "FROM base AS final" part, not
#                   here. We're copying the orig code to the build container and
#                   then from build to final. Should just copy from code to final.

# Move non-compiled code (Python, script) into place --------------------------

WORKDIR /src

# We need some way to tell the server that for modules built into the Docker 
# image, the venv will be in one place, but for modules downloaded at runtime,
# the venv for the module will be in a different place.
#
# We do this by having a modulesettings.docker.build.json file that has the
# settings for modules pre-installed into the image. this build.json file is 
# copied into the image and renamed to just .docker.json at Docker build time,
# and then when the module loads up, everything works.
# 
# If the module were downloaded and installed during runtime, then the usual 
# modulesettings.linux.json would be used, and then modulesettings.docker.json
# would then be loaded (if it existed). The modulesettings.docker.build.json
# file would be ignored.
#
# This enables us to have a modulesettings for inside a docker image, and module
# settings for modules outside the docker image.

COPY ["${MODULES_REPO_NAME}/CodeProject.AI-FaceProcessing/", "/app/publish/preinstalled-modules/FaceProcessing"]
RUN mv -f  /app/publish/preinstalled-modules/FaceProcessing/modulesettings.docker.build.json \
           /app/publish/preinstalled-modules/FaceProcessing/modulesettings.docker.json &&    \
    rm -rf /app/publish/preinstalled-modules/FaceProcessing/intelligencelayer/__pycache__ && \
    rm -f /app/publish/preinstalled-modules/FaceProcessing/*.zip                   \
          /app/publish/preinstalled-modules/FaceProcessing/package.bat             \
          /app/publish/preinstalled-modules/FaceProcessing/*.pyprog

COPY ["${MODULES_REPO_NAME}/CodeProject.AI-ObjectDetectionYOLOv5-3.1/", "/app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1"]
RUN mv -f /app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1/modulesettings.docker.build.jetson.json \
          /app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1/modulesettings.docker.json &&           \
    rm -rf /app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1/__pycache__ &&                         \
    rm -f /app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1/*.zip        \
          /app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1/package.bat  \
          /app/publish/preinstalled-modules/ObjectDetectionYOLOv5-3.1/*.pyprog

COPY ["${MODULES_REPO_NAME}/CodeProject.AI-bjectDetectionCoral/", "/app/publish/preinstalled-modules/ObjectDetectionCoral"]
RUN mv -f /app/publish/preinstalled-modules/ObjectDetectionCoral/modulesettings.docker.build.jetson.json \
          /app/publish/preinstalled-modules/ObjectDetectionCoral/modulesettings.docker.json &&           \
    rm -rf /app/publish/preinstalled-modules/ObjectDetectionCoral/__pycache__ &&                         \
    rm -f /app/publish/preinstalled-modules/ObjectDetectionCoral/*.zip        \
          /app/publish/preinstalled-modules/ObjectDetectionCoral/package.bat  \
          /app/publish/preinstalled-modules/ObjectDetectionCoral/*.pyprog


# SDK and install scripts
COPY ["/${REPO_NAME}/src/SDK/Python",        "/app/publish/SDK/Python"]
COPY ["/${REPO_NAME}/src/SDK/install.sh",    "/app/publish/SDK/install.sh"]
COPY ["/${REPO_NAME}/src/server/install.sh", "/app/publish/server/install.sh"]
COPY ["/${REPO_NAME}/src/scripts",           "/app/publish/scripts"]
COPY ["/${REPO_NAME}/src/setup.sh",          "/app/publish/setup.sh"]

# Cleanup / setup
RUN rm -rf /app/publish/SDK/Python/__pycache__ \
    mkdir /app/publish/runtimes

# END REVIEW ===================================================================


# CREATE THE FINAL IMAGE ======================================================

FROM base AS final

# Note: UBUNTU_VERSION, DOTNET_VERSION and all ENV declared in 'base' are still here.

ARG REPO_NAME
ENV REPO_NAME=$REPO_NAME

# Move published server and modules into place --------------------------------

WORKDIR /app
COPY --from=build /app/publish .

# Install required Python packages --------------------------------------------

# See https://towardsdatascience.com/how-to-shrink-numpy-scipy-pandas-and-matplotlib-for-your-data-product-4ec8d7e86ee4
# for a discussion on reducing PIP install sizes. That article is woefully out of date, with the
# --compile and --global-option now deprecated, the CLFAGS to nothing, but the --no-cache-dir does help

RUN python3.8 -m pip --no-cache-dir install \
    -r "/app/SDK/Python/requirements.txt" \
    -r "/app/preinstalled-modules/FaceProcessing/requirements.linux.cuda${CUDA_MAJOR}.txt" \
    -r "/app/preinstalled-modules/ObjectDetectionYOLOv5-6.2/requirements.linux.cuda${CUDA_MAJOR}.txt"

#RUN python3.9 -m pip --no-cache-dir install \
#    -r /app/SDK/Python/requirements.txt 

# Add folders for storing persisted user data and modules. This should be mapped
# to a folder on the host. Typically C:\ProgramData\CodeProject\AI on Windows, 
# /etc/codeproject/ai on Linux, and /Library/Application Support/CodeProject/AI 
# on macOS.
# We also make a .vscode folder so we have some bits in place if we wish to run
# VSCode inside the container
RUN mkdir --parents /etc/codeproject/ai                 && \
    mkdir --parents /app/downloads/modules /app/modules && \
    mkdir /app/.vscode

COPY [ "/${REPO_NAME}/.vscode/launch.docker.json", "/app/.vscode/launch.json" ]
COPY [ "/${REPO_NAME}/.vscode/tasks.docker.json",  "/app/.vscode/tasks.json" ]

WORKDIR /app/server
# ENTRYPOINT ["dotnet CodeProject.AI.Server.dll"]

CMD ["dotnet", "CodeProject.AI.Server.dll"]

# For debug
# ENTRYPOINT ["tail", "-f", "/dev/null"]